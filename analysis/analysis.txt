Put your name and netid here
Brian Du
bd121

(1) Run the program BenchmarkForAutocomplete and copy/paste the 
results here this for #matches = 20

search	size	#match	binary	brute
		456976	20	0,3006	0,0141
a		17576	20	0,0065	0,0117
b		17576	20	0,0085	0,0069
c		17576	20	0,0099	0,0065
x		17576	20	0,0057	0,0050
y		17576	20	0,0057	0,0135
z		17576	20	0,0076	0,0069
aa		676		20	0,0002	0,0096
az		676		20	0,0006	0,0097
za		676		20	0,0006	0,0177
zz		676		20	0,0005	0,0062

(2) Run the program again for #matches = 10000, paste the results, 
and then make any conclusions about how the # matches 
effects the runtime. 

search	size	#match	binary	brute
		456976	10000	0,2598	0,0578
a		17576	10000	0,0102	0,0112
b		17576	10000	0,0067	0,0107
c		17576	10000	0,0058	0,0105
x		17576	10000	0,0065	0,0107
y		17576	10000	0,0054	0,0104
z		17576	10000	0,0079	0,0159
aa		676		10000	0,0002	0,0061
az		676		10000	0,0002	0,0050
za		676		10000	0,0002	0,0050
zz		676		10000	0,0003	0,0050

The number of matches makes no difference (negligible) in runtime for the binary and brute implementations. Depending on 
the search query, the runtime for #matches=20 is greater than or less than that for #matches=10000. This makes sense when
considering the big O runtime complexities for binary and brute; #matches is not the highest power factor in the big O
complexities and thus has no significant impact on the overall runtime. 

(3) Copy/paste the code from BruteAutocomplete.topMatches below. 
Explain what the Big-Oh complexity of the entire loop: 
for(Term t : myTerms) {...} 
is in terms of N, the number of elements in myTerms and 
M, the number of terms that match the prefix. 
Assume that every priority-queue operation runs in O(log k) time. 
Explain your answer which should be in terms of N, M, and k.

@Override
	public List<Term> topMatches(String prefix, int k) {
		if (k < 0) {
			throw new IllegalArgumentException("Illegal value of k:"+k);
		}
		
		// maintain pq of size k
		PriorityQueue<Term> pq = new PriorityQueue<Term>(10, new Term.WeightOrder());
		for (Term t : myTerms) {
			if (!t.getWord().startsWith(prefix))
				continue;
			if (pq.size() < k) {
				pq.add(t);
			} else if (pq.peek().getWeight() < t.getWeight()) {
				pq.remove();
				pq.add(t);
			}
		}
		int numResults = Math.min(k, pq.size());
		LinkedList<Term> ret = new LinkedList<>();
		for (int i = 0; i < numResults; i++) {
			ret.addFirst(pq.remove());
		}
		return ret;
	}

	The for (Term t : myTerms) { loop has runtime complexity of N + Mlogk because it will look through
	all N terms in MyTerms. Of the N terms, there will be M matches, and k of them are loaded into a 
	PriorityQueue for Mlogk complexity. Thus the total complexity is N + Mlogk.  
(4) Explain why the last for loop in BruteAutocomplete.topMatches 
uses a LinkedList (and not an ArrayList) 
AND why the PriorityQueue uses Term.WeightOrder to get 
the top k heaviest matches -- rather than 
using Term.ReverseWeightOrder.

A LinkedList is used instead of an ArrayList because adding to the front of a LinkedList is more efficient
since all the elements do not need to shift one index as they do in an ArrayList. Term.WeightOrder is used
instead of Term.ReverseWeightOrder so that the terms are arranged in order with the lightest at
the front and heaviest at the back of the queue. This way, when terms are removed from the queue and added
one by one to the beginning of the LinkedList, the heaviest will be the last added and the first term in
the LinkedList, as desired.

because with the weights arranged in ascending order in the Queue, the
terms with the heaviest weight will be the first taken from the PriorityQueue. Thus only the first k
terms need to be taken from the PriorityQueue.

(5) Explain what the runtime of the 
BinarySearchAutocomplete.topMatches code that you 
implemented is by copy/pasting the code below 
and explaining your answer in terms of N, M, and k.

	public List<Term> topMatches(String prefix, int k) {

		if(prefix == null )
			throw new NullPointerException("prefix is null");
		
		if (k < 0) {
			throw new IllegalArgumentException("Illegal value of k:"+k);
		}
		//f is the index of First element that matches prefix
		int f = firstIndexOf(myTerms, new Term(prefix, 0), new Term.PrefixOrder(prefix.length()));
		
		//l is the index of Last element that matches prefix
		int l = lastIndexOf(myTerms, new Term(prefix, 0), new Term.PrefixOrder(prefix.length()));
		
		ArrayList<Term> myList = new ArrayList<Term>();
		
		if(f == 0 && l == myTerms.length - 1)
			myList.addAll(Arrays.asList(myTerms));
		else
		if(f >=0 && l >=0) {
			
			for(int i = f; i <= l; i++)
					myList.add(myTerms[i]);
		}
		
		Collections.sort(myList, new Term.ReverseWeightOrder());
		
		if(k >= myList.size()) {
			
			return myList;
		}
		else {
			
			ArrayList<Term> ret = new ArrayList<>();
			
			for(int i = 0; i < k; i++)
				ret.add(myList.get(i));
			
			return ret;
		}
	}	
	
	The big O for index searching with prefix is 2O(logN) or O(logN).
	The big O complexity of converting array to list is O(M).
	The big O for for sorting all M elements that match prefix is M*O(logM).
	The big O for getting the top k that match is O(k) or O(1).
	
	Together, this is O(logN + M + MlogM + k) or O(logN + M + MlogM + 1).
	

